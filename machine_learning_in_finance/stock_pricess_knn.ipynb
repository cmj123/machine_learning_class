{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Stock Prices - K-nearest neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Key libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function - Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(stock_symbol, start_date, end_date, lags=5):\n",
    "    # Fetch the stock data from Yahoo Finance\n",
    "    df = web.DataReader(stock_symbol, \"yahoo\", start_date, end_date)\n",
    "#     print(df.head())\n",
    "    \n",
    "    # create a new dataframe \n",
    "    # we want to use additional features: lagged returns... today's returns, yesterday's returns etc\n",
    "    tslag = pd.DataFrame(index=df.index)\n",
    "    tslag[\"Today\"] = df[\"Adj Close\"]\n",
    "    tslag[\"Volume\"] = df[\"Volume\"]\n",
    "#     print(tslag.head())\n",
    "    \n",
    "    # Create the shifted lag series of prior trading close values \n",
    "    for i in range(0, lags):\n",
    "        tslag[\"Lags%s\" %str(i+1)] = df[\"Adj Close\"].shift(i+1)\n",
    "    \n",
    "#     print(tslag.head())\n",
    "    \n",
    "    # create the returns dataframe\n",
    "    dfret = pd.DataFrame(index=tslag.index)\n",
    "    dfret[\"Volume\"] = tslag[\"Volume\"]\n",
    "    dfret[\"Today\"] = tslag[\"Today\"].pct_change()*100.0\n",
    "#     print(dfret.head())\n",
    "    \n",
    "    # Create the lagged returns columns\n",
    "    for i in range(0, lags):\n",
    "        dfret[\"Lag%s\" %str(i+1)] = tslag[\"Lags%s\" %str(i+1)].pct_change()*100.0\n",
    "#     print(dfret.head())\n",
    "        \n",
    "    # \"Direction\" column (+1 or -1) indicating an up/down day\n",
    "    dfret[\"Direction\"] = np.sign(dfret[\"Today\"])\n",
    "#     print(dfret.head())\n",
    "    \n",
    "    # Because of the shifts there are NaN values... we want to get rid of those NaNs\n",
    "    dfret.drop(dfret.index[:6], inplace=True)\n",
    "#     print(dfret.head())\n",
    "    \n",
    "    return dfret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataset(stock_symbol = ['AAPL'], start_date=datetime(2012,1,1), end_date=datetime(2017,5,31), lags=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run - knn model for stock price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.466\n",
      "Confusion matric: \n",
      "[[31  0 40]\n",
      " [ 1  0  2]\n",
      " [12  0 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esuabomdijemeni/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Create a lagged series of the S&P US stock market index\n",
    "    data = create_dataset(\"AAPL\", datetime(2012,1,1), datetime(2017,5,31), lags=5)\n",
    "    \n",
    "    # Use the prior days of returns as predictor\n",
    "    # values, with direction as the response \n",
    "    X = data[['Lag1','Lag2','Lag3','Lag4']]\n",
    "    y = data[\"Direction\"]\n",
    "    \n",
    "    # The test data is split into two parts: before and after 1st Jan 2005\n",
    "    start_test = datetime(2017, 1,1)\n",
    "    \n",
    "    # Create training and test sets\n",
    "    X_train = X[X.index < start_test]\n",
    "    X_test = X[X.index >= start_test]\n",
    "    y_train = y[y.index < start_test]\n",
    "    y_test = y[y.index >= start_test]\n",
    "    \n",
    "    # we use K as the machine learning model\n",
    "#     model = KNeighborsClassifier(300)\n",
    "#     model = LinearSVC()\n",
    "    model = SVC(C=1000000.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0001, kernel='rbf', \n",
    "                max_iter=1, probability=False)\n",
    "    \n",
    "    #train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make an array of predictions on the test set\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # Output the hit-rate and the confusion matric for the model\n",
    "    print(\"Accuracy of model: %0.3f\" % model.score(X_test,y_test))\n",
    "    print(\"Confusion matric: \\n%s\" % confusion_matrix(pred, y_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
